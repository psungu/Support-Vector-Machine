{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>CMPE 462 - Project 2<br>Implementing an SVM Classifier<br>Due: May 18, 2020, 23:59</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Student ID1:** 2014400051\n",
    "* **Student ID2:** 2018400291\n",
    "* **Student ID3:** 2019705072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this project, you are going to implement SVM. For this purpose, a data set (data.mat) is given to you. You can load the mat dataset into Python using the function `loadmat` in `Scipy.io`. When you load the data, you will obtain a dictionary object, where `X` stores the data matrix and `Y` stores the labels. You can use the first 150 samples for training and the rest for testing. In this project, you will use the software package [`LIBSVM`](http://www.csie.ntu.edu.tw/~cjlin/libsvm/) to implement SVM. Note that `LIBSVM` has a [`Python interface`](https://github.com/cjlin1/libsvm/tree/master/python), so you can call the SVM functions in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting libsvm\n",
      "Installing collected packages: libsvm\n",
      "Successfully installed libsvm-3.23.0.4\n",
      "Collecting PTable\n",
      "Installing collected packages: PTable\n",
      "Successfully installed PTable-0.9.2\n"
     ]
    }
   ],
   "source": [
    "# Installing required libraries before we start using them\n",
    "!pip3 install libsvm \n",
    "!pip3 install PTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio  #Import required libraries\n",
    "from libsvm.svmutil import *\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "dic = spio.loadmat(\"data.mat\")\n",
    "\n",
    "train_matrix, train_labels = dic['X'][:150], dic['Y'][:150] # Train set and labels\n",
    "test_matrix, test_labels = dic['X'][150:], dic['Y'][150:] # Test set and labels\n",
    "\n",
    "train_labels = train_labels.reshape((train_labels.shape[0],)) #Convert datasets to 1D numpy array shape\n",
    "test_labels = test_labels.reshape((test_labels.shape[0],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - 30 pts\n",
    "\n",
    "Train a hard margin linear SVM and report both train and test classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes a parameter for svm_train method of libsvm package\n",
    "# trains a model using the train set of data.mat\n",
    "# uses this model to classify samples\n",
    "# Calculates both train accuracy and test accuracy\n",
    "\n",
    "def svm_function(params):\n",
    "    global train_labels, train_matrix, test_labels, test_matrix # data is obtained from global test and train data.\n",
    "    m = svm_train(train_labels, train_matrix, params) # libsvm function to train model with train set\n",
    "    \n",
    "     # Predict accuracy of Training set\n",
    "    result = [] # result is will be a tuple of train accuracy and test accuracy\n",
    "    p_label, p_acc, p_val = svm_predict(train_labels, train_matrix, m, '-q') # Model predictions and accuracy are returned from the function.\n",
    "    result.append(str(round(p_acc[0], 4))) # train set accuracy is rounded to 4 decimal points and returned as string\n",
    "    \n",
    "    # Predict accuracy of Test set\n",
    "    p_label, p_acc, p_val = svm_predict(test_labels, test_matrix, m, '-q') # -q is abbreviation for quite mode, prevents function to output results\n",
    "    result.append(str(round(p_acc[0], 4))) # test set accuracy is rounded to 4 decimal points and returned as string\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Margin SVM\n",
      "Train classification accuracy: 74.6667\n",
      "Test classification accuracy: 77.5\n"
     ]
    }
   ],
   "source": [
    "res = svm_function('-t 0 -c 100000000') # Hard margin SVM, c-value is selected very large number, -t 0 means linear kernel\n",
    "print('Hard Margin SVM')\n",
    "print('Train classification accuracy: ' + res[0])\n",
    "print('Test classification accuracy: ' + res[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - 40 pts\n",
    "\n",
    "Train soft margin SVM for different values of the parameter $C$, and with different kernel functions. Systematically report your results. For instance, report the performances of different kernels for a fixed $C$, then report the performance for different $C$ values for a fixed kernel, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Kernel, Different C-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+\n",
      "|                       Kernel -> Radial basis function : exp(-1*|u-v|^2)                        |\n",
      "+----------------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|    C Value     |  0.001  |   0.01  |   0.1   |    1    |    10   |   100   |   1000  |  10000  |\n",
      "+----------------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "| Train Accuracy | 53.3333 | 53.3333 | 83.3333 | 86.6667 | 95.3333 | 99.3333 |  100.0  |  100.0  |\n",
      "| Test Accuracy  | 58.3333 | 58.3333 | 84.1667 | 84.1667 |   77.5  | 78.3333 | 76.6667 | 76.6667 |\n",
      "+----------------+---------+---------+---------+---------+---------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Radial basis function: exp(-1*|u-v|^2)\n",
    "c_v = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000] # Different c values to train models\n",
    "results = []\n",
    "\n",
    "# -t 2 means RBF Kernel\n",
    "for c in c_v: # for every c-value we create new parameters to be sent to our svm_function\n",
    "    results.append(svm_function(f'-t 2 -c {c}')) \n",
    "\n",
    "# Pretty table helps us visualise results with changing parameters in a nice way\n",
    "# You can add more c-values to the list c_v and run the cell again. \n",
    "table = PrettyTable() \n",
    "table.title = 'Kernel -> Radial basis function : exp(-1*|u-v|^2)'\n",
    "table.field_names = [\"C Value\"]+[str(c) for c in c_v]\n",
    "table.add_row([\"Train Accuracy\"] +[res[0] for res in results]) # First element of tuple is training accuraccy\n",
    "table.add_row([\"Test Accuracy\"]+[res[1] for res in results]) # Second element of tuple is test accuracy\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+\n",
      "|                                 Kernel -> Polynomial: (u'*v)^2                                 |\n",
      "+----------------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|    C Value     |  0.001  |   0.01  |   0.1   |    1    |    10   |   100   |   1000  |  10000  |\n",
      "+----------------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "| Train Accuracy | 53.3333 | 53.3333 |   56.0  | 85.3333 | 88.6667 | 97.3333 | 99.3333 |  100.0  |\n",
      "| Test Accuracy  | 58.3333 | 58.3333 | 59.1667 | 78.3333 | 79.1667 | 76.6667 | 73.3333 | 69.1667 |\n",
      "+----------------+---------+---------+---------+---------+---------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Kernel: Polynomial: (u'*v)^2\n",
    "\n",
    "c_v = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "results = []\n",
    "\n",
    "# -t 1 means Polynomial Kernel\n",
    "# -d 2 means degree\n",
    "\n",
    "for c in c_v: # for every c-value we create new parameters to be sent to our svm_function\n",
    "    results.append(svm_function(f'-t 1 -d 2 -c {c}'))\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title ='Kernel -> Polynomial: (u\\'*v)^2'\n",
    "\n",
    "table.field_names = [\"C Value\"]+[str(c) for c in c_v]\n",
    "table.add_row([\"Train Accuracy\"] +[res[0] for res in results])\n",
    "table.add_row([\"Test Accuracy\"]+[res[1] for res in results])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------+\n",
      "|                                Kernel -> Sigmoid: tanh(u'*v)                                |\n",
      "+----------------+---------+---------+---------+---------+------+---------+---------+---------+\n",
      "|    C Value     |  0.001  |   0.01  |   0.1   |    1    |  10  |   100   |   1000  |  10000  |\n",
      "+----------------+---------+---------+---------+---------+------+---------+---------+---------+\n",
      "| Train Accuracy | 53.3333 | 53.3333 |   82.0  | 82.6667 | 78.0 | 76.6667 | 75.3333 | 75.3333 |\n",
      "| Test Accuracy  | 58.3333 | 58.3333 | 84.1667 | 84.1667 | 80.0 |   72.5  | 74.1667 | 74.1667 |\n",
      "+----------------+---------+---------+---------+---------+------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Kernel: Sigmoid tanh(u'*v)\n",
    "\n",
    "c_v = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "results = []\n",
    "\n",
    "# -t 3 means Sigmoid Kernel\n",
    "for c in c_v:\n",
    "    results.append(svm_function(f'-t 3 -c {c}'))\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title ='Kernel -> Sigmoid: tanh(u\\'*v)'\n",
    "\n",
    "table.field_names = [\"C Value\"]+[str(c) for c in c_v]\n",
    "table.add_row([\"Train Accuracy\"] +[res[0] for res in results])\n",
    "table.add_row([\"Test Accuracy\"]+[res[1] for res in results])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+\n",
      "|                                     Kernel -> Linear: u'*v                                     |\n",
      "+----------------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|    C Value     |  0.001  |   0.01  |   0.1   |    1    |    10   |   100   |   1000  |  10000  |\n",
      "+----------------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "| Train Accuracy | 53.3333 | 82.6667 |   86.0  | 86.6667 | 88.6667 | 88.6667 |   90.0  |   90.0  |\n",
      "| Test Accuracy  | 58.3333 | 84.1667 | 83.3333 |   85.0  | 81.6667 | 81.6667 | 81.6667 | 81.6667 |\n",
      "+----------------+---------+---------+---------+---------+---------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Kernel: Linear: u'*v\n",
    "\n",
    "c_v = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "results = []\n",
    "\n",
    "# -t 0 means Linear Kernel\n",
    "for c in c_v:\n",
    "    results.append(svm_function(f'-t 0 -c {c}'))\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title ='Kernel -> Linear: u\\'*v'\n",
    "\n",
    "table.field_names = [\"C Value\"]+[str(c) for c in c_v]\n",
    "table.add_row([\"Train Accuracy\"] +[res[0] for res in results])\n",
    "table.add_row([\"Test Accuracy\"]+[res[1] for res in results])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------+\n",
      "|                                Kernel -> Polynomial: (u'*v)^3                               |\n",
      "+----------------+---------+---------+---------+------+---------+---------+---------+---------+\n",
      "|    C Value     |  0.001  |   0.01  |   0.1   |  1   |    10   |   100   |   1000  |  10000  |\n",
      "+----------------+---------+---------+---------+------+---------+---------+---------+---------+\n",
      "| Train Accuracy | 53.3333 | 53.3333 | 53.3333 | 86.0 |   94.0  | 98.6667 |  100.0  |  100.0  |\n",
      "| Test Accuracy  | 58.3333 | 58.3333 | 58.3333 | 82.5 | 80.8333 |   75.0  | 75.8333 | 75.8333 |\n",
      "+----------------+---------+---------+---------+------+---------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Kernel: Polynomial: (u'*v)^3\n",
    "\n",
    "c_v = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "results = []\n",
    "\n",
    "# -t 1 means Polynomial Kernel\n",
    "# -d 3 means degree 3\n",
    "for c in c_v:\n",
    "    results.append(svm_function(f'-t 1 -d 3 -c {c}'))\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title ='Kernel -> Polynomial: (u\\'*v)^3'\n",
    "\n",
    "table.field_names = [\"C Value\"]+[str(c) for c in c_v]\n",
    "table.add_row([\"Train Accuracy\"] +[res[0] for res in results])\n",
    "table.add_row([\"Test Accuracy\"]+[res[1] for res in results])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed C, Different Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------+\n",
      "|                                    Fixed C = 0.01                                    |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n",
      "|     Kernel     | polynomial(U'V)^3 | polynomial(U'V)^2 |  linear | sigmoid |   RBF   |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n",
      "| Train Accuracy |      53.3333      |      53.3333      | 82.6667 | 53.3333 | 53.3333 |\n",
      "| Test Accuracy  |      58.3333      |      58.3333      | 84.1667 | 58.3333 | 58.3333 |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "kernels = ['-t 1 -d 3', '-t 1 -d 2', '-t 0', '-t 3', '-t 2'] \n",
    "kernel_names = ['polynomial(U\\'V)^3', 'polynomial(U\\'V)^2', 'linear', 'sigmoid', 'RBF']\n",
    "\n",
    "# kernels and kernel_names lists are complementary. Elements of both lists with same indices are pairs.\n",
    "# You can add new kernel parameters to 'kernels' and add its definiton to 'kernel_names' and run the cell again\n",
    "results = []\n",
    "\n",
    "# For each kernel parameter, we create new parameters and send to our svm_function for fixed C = 0.01.\n",
    "for kernel in kernels:\n",
    "    results.append(svm_function(f'{kernel} -c 0.01'))\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title ='Fixed C = 0.01'\n",
    "\n",
    "table.field_names = [\"Kernel\"]+[kernel_name for kernel_name in kernel_names]\n",
    "table.add_row([\"Train Accuracy\"] +[res[0] for res in results])\n",
    "table.add_row([\"Test Accuracy\"]+[res[1] for res in results])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------+\n",
      "|                                    Fixed C = 0.1                                     |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n",
      "|     Kernel     | polynomial(U'V)^3 | polynomial(U'V)^2 |  linear | sigmoid |   RBF   |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n",
      "| Train Accuracy |      53.3333      |        56.0       |   86.0  |   82.0  | 83.3333 |\n",
      "| Test Accuracy  |      58.3333      |      59.1667      | 83.3333 | 84.1667 | 84.1667 |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "kernels = ['-t 1 -d 3', '-t 1 -d 2', '-t 0', '-t 3', '-t 2'] \n",
    "kernel_names = ['polynomial(U\\'V)^3', 'polynomial(U\\'V)^2', 'linear', 'sigmoid', 'RBF']\n",
    "results = []\n",
    "\n",
    "# kernels and kernel_names lists are complementary. Elements of both lists with same indices are pairs.\n",
    "# You can add new kernel parameters to 'kernels' and add its definiton to 'kernel_names' and run the cell again\n",
    "for kernel in kernels:\n",
    "    results.append(svm_function(f'{kernel} -c 0.1'))\n",
    "\n",
    "# For each kernel parameter, we create new parameters and send to our svm_function for fixed C = 0.1.\n",
    "table = PrettyTable()\n",
    "table.title ='Fixed C = 0.1'\n",
    "\n",
    "table.field_names = [\"Kernel\"]+[kernel_name for kernel_name in kernel_names]\n",
    "table.add_row([\"Train Accuracy\"] +[res[0] for res in results])\n",
    "table.add_row([\"Test Accuracy\"]+[res[1] for res in results])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------+\n",
      "|                                     Fixed C = 1                                      |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n",
      "|     Kernel     | polynomial(U'V)^3 | polynomial(U'V)^2 |  linear | sigmoid |   RBF   |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n",
      "| Train Accuracy |        86.0       |      85.3333      | 86.6667 | 82.6667 | 86.6667 |\n",
      "| Test Accuracy  |        82.5       |      78.3333      |   85.0  | 84.1667 | 84.1667 |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "kernels = ['-t 1 -d 3', '-t 1 -d 2', '-t 0', '-t 3', '-t 2'] \n",
    "kernel_names = ['polynomial(U\\'V)^3', 'polynomial(U\\'V)^2', 'linear', 'sigmoid', 'RBF']\n",
    "results = []\n",
    "\n",
    "# kernels and kernel_names lists are complementary. Elements of both lists with same indices are pairs.\n",
    "# You can add new kernel parameters to 'kernels' and add its definiton to 'kernel_names' and run the cell again\n",
    "for kernel in kernels:\n",
    "    results.append(svm_function(f'{kernel} -c 1'))\n",
    "\n",
    "# For each kernel parameter, we create new parameters and send to our svm_function for fixed C = 1.\n",
    "table = PrettyTable()\n",
    "table.title ='Fixed C = 1'\n",
    "\n",
    "table.field_names = [\"Kernel\"]+[kernel_name for kernel_name in kernel_names]\n",
    "table.add_row([\"Train Accuracy\"] +[res[0] for res in results])\n",
    "table.add_row([\"Test Accuracy\"]+[res[1] for res in results])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------+\n",
      "|                                     Fixed C = 10                                     |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n",
      "|     Kernel     | polynomial(U'V)^3 | polynomial(U'V)^2 |  linear | sigmoid |   RBF   |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n",
      "| Train Accuracy |        94.0       |      88.6667      | 88.6667 |   78.0  | 95.3333 |\n",
      "| Test Accuracy  |      80.8333      |      79.1667      | 81.6667 |   80.0  |   77.5  |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "kernels = ['-t 1 -d 3', '-t 1 -d 2', '-t 0', '-t 3', '-t 2'] \n",
    "kernel_names = ['polynomial(U\\'V)^3', 'polynomial(U\\'V)^2', 'linear', 'sigmoid', 'RBF']\n",
    "results = []\n",
    "\n",
    "# kernels and kernel_names lists are complementary. Elements of both lists with same indices are pairs.\n",
    "# You can add new kernel parameters to 'kernels' and add its definiton to 'kernel_names' and run the cell again\n",
    "for kernel in kernels:\n",
    "    results.append(svm_function(f'{kernel} -c 10'))\n",
    "\n",
    "# For each kernel parameter, we create new parameters and send to our svm_function for fixed C = 10\n",
    "table = PrettyTable()\n",
    "table.title ='Fixed C = 10'\n",
    "\n",
    "table.field_names = [\"Kernel\"]+[kernel_name for kernel_name in kernel_names]\n",
    "table.add_row([\"Train Accuracy\"] +[res[0] for res in results])\n",
    "table.add_row([\"Test Accuracy\"]+[res[1] for res in results])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------+\n",
      "|                                    Fixed C = 100                                     |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n",
      "|     Kernel     | polynomial(U'V)^3 | polynomial(U'V)^2 |  linear | sigmoid |   RBF   |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n",
      "| Train Accuracy |      98.6667      |      97.3333      | 88.6667 | 76.6667 | 99.3333 |\n",
      "| Test Accuracy  |        75.0       |      76.6667      | 81.6667 |   72.5  | 78.3333 |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "kernels = ['-t 1 -d 3', '-t 1 -d 2', '-t 0', '-t 3', '-t 2'] \n",
    "kernel_names = ['polynomial(U\\'V)^3', 'polynomial(U\\'V)^2', 'linear', 'sigmoid', 'RBF']\n",
    "results = []\n",
    "\n",
    "# kernels and kernel_names lists are complementary. Elements of both lists with same indices are pairs.\n",
    "# You can add new kernel parameters to 'kernels' and add its definiton to 'kernel_names' and run the cell again\n",
    "for kernel in kernels:\n",
    "    results.append(svm_function(f'{kernel} -c 100'))\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title ='Fixed C = 100'\n",
    "\n",
    "# For each kernel parameter, we create new parameters and send to our svm_function for fixed C = 100\n",
    "table.field_names = [\"Kernel\"]+[kernel_name for kernel_name in kernel_names]\n",
    "table.add_row([\"Train Accuracy\"] +[res[0] for res in results])\n",
    "table.add_row([\"Test Accuracy\"]+[res[1] for res in results])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------+\n",
      "|                                    Fixed C = 1000                                    |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n",
      "|     Kernel     | polynomial(U'V)^3 | polynomial(U'V)^2 |  linear | sigmoid |   RBF   |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n",
      "| Train Accuracy |       100.0       |      99.3333      |   90.0  | 75.3333 |  100.0  |\n",
      "| Test Accuracy  |      75.8333      |      73.3333      | 81.6667 | 74.1667 | 76.6667 |\n",
      "+----------------+-------------------+-------------------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "kernels = ['-t 1 -d 3', '-t 1 -d 2', '-t 0', '-t 3', '-t 2'] \n",
    "kernel_names = ['polynomial(U\\'V)^3', 'polynomial(U\\'V)^2', 'linear', 'sigmoid', 'RBF']\n",
    "results = []\n",
    "\n",
    "# kernels and kernel_names lists are complementary. Elements of both lists with same indices are pairs.\n",
    "# You can add new kernel parameters to 'kernels' and add its definiton to 'kernel_names' and run the cell again\n",
    "for kernel in kernels:\n",
    "    results.append(svm_function(f'{kernel} -c 1000'))\n",
    "\n",
    "# For each kernel parameter, we create new parameters and send to our svm_function for fixed C = 1000\n",
    "table = PrettyTable()\n",
    "table.title ='Fixed C = 1000'\n",
    "\n",
    "table.field_names = [\"Kernel\"]+[kernel_name for kernel_name in kernel_names]\n",
    "table.add_row([\"Train Accuracy\"] +[res[0] for res in results])\n",
    "table.add_row([\"Test Accuracy\"]+[res[1] for res in results])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - 15 pts\n",
    "\n",
    "Please report how the number of support vectors changes as the value of $C$ increases (while all other parameters remain the same). Discuss whether your observations match the theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains a model with train set using parameters and returns the number of support vectors of the model\n",
    "def get_number_of_sv(params):\n",
    "    global train_labels, train_matrix\n",
    "    m = svm_train(train_labels, train_matrix, params)\n",
    "    return m.get_nr_sv() # get_nr_sv means number of support vectors, utility function of libsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------+\n",
      "|                             Kernel -> Linear: u'*v                            |\n",
      "+---------------------------+-------+------+-----+----+----+-----+------+-------+\n",
      "|          C Value          | 0.001 | 0.01 | 0.1 | 1  | 10 | 100 | 1000 | 10000 |\n",
      "+---------------------------+-------+------+-----+----+----+-----+------+-------+\n",
      "| Number of Support Vectors |  140  | 118  |  74 | 58 | 51 |  50 |  49  |   49  |\n",
      "+---------------------------+-------+------+-----+----+----+-----+------+-------+\n"
     ]
    }
   ],
   "source": [
    "c_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "num_sv = [] # stores number of support vectors for each model trained with certain parameter c\n",
    "\n",
    "# For each c value, call our get_number_of_sv function and store result in num_sv\n",
    "for c in c_values:\n",
    "    num_sv.append(get_number_of_sv(f'-t 0 -c {c}'))\n",
    "    \n",
    "table = PrettyTable()\n",
    "\n",
    "table.title ='Kernel -> Linear: u\\'*v' # Model is trained with Linear kernel\n",
    "\n",
    "table.field_names = [\"C Value\"]+[str(c) for c in c_values]\n",
    "table.add_row([\"Number of Support Vectors\"]+num_sv)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* C is penalty term on the slack variables, measures the degree to which the margin constraints are violated. If we increase C-value, a greater penalty is applied on violators and less data points are tolerated. So, SVM margin will be narrower. Thus, less data points are support vectors. Theory says When we increase value of C, number of support vectors decreases. Our observations match the theory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - 15 pts\n",
    "\n",
    "Please investigate the changes in the hyperplane when you remove one of the support vectors, vs., one data point that is not a support vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes data matrix and trained model, returns weight, number of support vectors and norm of weight\n",
    "def get_weight(data,m):\n",
    "    \n",
    "    #declaring coefficent matrix and matrix of support vectors\n",
    "    SV_coef = np.zeros(shape=(m.get_nr_sv()))\n",
    "    SVs = np.zeros(shape=(m.get_nr_sv(),data.shape[1]))\n",
    "\n",
    "    #filling coefficent matrix and matrix of support vectors with proper values\n",
    "    for index in range(0,m.get_nr_sv()):\n",
    "        SV_coef[index] = m.get_sv_coef()[index][0]\n",
    "        SVs[index] = data[m.get_sv_indices()[index]-1]\n",
    "        \n",
    "    #calculating weight vector via dot product of coefficent matrix and matrix of support vectors \n",
    "    weight = np.dot(SV_coef.transpose(),SVs)\n",
    "\n",
    "    return weight, m.get_nr_sv() ,np.linalg.norm(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deletes a support vector with given index, returns weight, number of support vectors and norm of weight\n",
    "def delete_sv(data,labels,m,param,index):\n",
    "    \n",
    "    #deletes proper row of data matrix\n",
    "    new_set = np.delete(data,index-1,0)\n",
    "    #deletes proper row of label vector\n",
    "    new_labels = np.delete(labels,index-1,0)\n",
    "    #getting model \n",
    "    m = svm_train(new_labels,new_set,param)\n",
    "    #getting weight vector,number of support vectors and norm of weight\n",
    "    weight, Number_Of_Svs, w_norm = get_weight(new_set,m)\n",
    "   \n",
    "    return weight,Number_Of_Svs ,w_norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deletes a data point that is not a support vector, returns weight, number of support vectors and norm of weight\n",
    "def delete_dp(data,labels,m,param):\n",
    "    comparison = np.arange(data.shape[0])+1\n",
    "    sv_indices = m.get_sv_indices()\n",
    "    \n",
    "    weight=0\n",
    "    Number_Of_Svs=0\n",
    "    w_norm = 0\n",
    "\n",
    "    for index in comparison:\n",
    "        if index not in sv_indices:\n",
    "            \n",
    "            #deletes proper row of data matrix\n",
    "            new_set = np.delete(data,index-1,0)\n",
    "            #deletes proper row of label vector\n",
    "            new_labels = np.delete(labels,index-1,0)\n",
    "            #getting model \n",
    "            m = svm_train(new_labels,new_set,param)\n",
    "            #getting weight vector,number of support vectors and norm of weight\n",
    "            weight,Number_Of_Svs, w_norm= get_weight(new_set,m)\n",
    "            break\n",
    "            \n",
    "    return weight, Number_Of_Svs , w_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: [-1.30726513  0.52514823  1.34794553  1.38300601  1.61374734  0.15936149\n",
      "  0.13144559 -1.8510571  -0.0279832  -0.07509238  0.07069583  2.72990177\n",
      "  0.44450478]\n",
      "Norm of the weight: 4.4101043605317525\n",
      "Number of Support Vectors: 51\n"
     ]
    }
   ],
   "source": [
    "#linear kernel wih C=10\n",
    "param = '-t 0 -c 10'\n",
    "m = svm_train(train_labels,train_matrix,param)\n",
    "#getting weight vector,number of support vectors and norm of weight\n",
    "weight, Number_Of_Svs, w_norm = get_weight(train_matrix,m)\n",
    "\n",
    "comparison = w_norm #to use in comparison\n",
    "\n",
    "print(f\"Weight: {weight}\")\n",
    "print(f\"Norm of the weight: {w_norm}\")\n",
    "print(f\"Number of Support Vectors: {Number_Of_Svs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing one data point that is not a support vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: [-1.30726513  0.52514823  1.34794553  1.38300601  1.61374734  0.15936149\n",
      "  0.13144559 -1.8510571  -0.0279832  -0.07509238  0.07069583  2.72990177\n",
      "  0.44450478]\n",
      "Norm of the weight: 4.410104360531701\n",
      "Number of Support Vectors: 51\n"
     ]
    }
   ],
   "source": [
    "#removing one data point that is not a support vector.\n",
    "weight, Number_Of_Svs, w_norm= delete_dp(train_matrix,train_labels,m,param)\n",
    "\n",
    "print(f\"Weight: {weight}\")\n",
    "print(f\"Norm of the weight: {w_norm}\")\n",
    "print(f\"Number of Support Vectors: {Number_Of_Svs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing one of the support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: [-1.35468538  0.52540875  1.34077722  1.38151342  1.63622204  0.22703252\n",
      "  0.16792452 -1.97393535 -0.00791992 -0.16670834  0.01305132  2.50296982\n",
      "  0.51196652]\n",
      "Norm of the weight: 4.3618651742011005\n",
      "Number of Support Vectors: 53\n"
     ]
    }
   ],
   "source": [
    "#removing one of the support vectors\n",
    "sv_indices = m.get_sv_indices()\n",
    "weight, Number_Of_Svs, w_norm = delete_sv(train_matrix,train_labels,m,param,sv_indices[1])\n",
    "\n",
    "print(f\"Weight: {weight}\")\n",
    "print(f\"Norm of the weight: {w_norm}\")\n",
    "print(f\"Number of Support Vectors: {Number_Of_Svs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics about removing one of the support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51 support vectors.\n",
      "36 times norm of weight decreased and margin increased. Also, elements of weight vector changed.\n",
      "15 times norm of weight increased and margin decreased. Also, elements of weight vector changed.\n",
      "0 times norm of weight and margin did not change.\n"
     ]
    }
   ],
   "source": [
    "#number of support vectors\n",
    "number = m.get_nr_sv()\n",
    "#to store informations\n",
    "margin_inc = 0\n",
    "margin_dec = 0\n",
    "margin_stb = 0\n",
    "\n",
    "#iterates number of support vectors times\n",
    "for indice in sv_indices:\n",
    "    weight, Number_Of_Svs, w_norm = delete_sv(train_matrix,train_labels,m,param,indice)\n",
    "    #if norm of weight decreased, margin increased\n",
    "    if w_norm < comparison:\n",
    "        margin_inc = margin_inc+1\n",
    "    #if norm of weight increased, margin decreased\n",
    "    elif w_norm > comparison:\n",
    "        margin_dec = margin_dec+1\n",
    "    else:\n",
    "        margin_stb = margin_stb+1\n",
    "        \n",
    "\n",
    "\n",
    "print(f\"There are {number} support vectors.\")\n",
    "print(f\"{margin_inc} times norm of weight decreased and margin increased. Also, elements of weight vector changed.\")\n",
    "print(f\"{margin_dec} times norm of weight increased and margin decreased. Also, elements of weight vector changed.\")\n",
    "print(f\"{margin_stb} times norm of weight and margin did not change.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Task - 10 pts\n",
    "\n",
    "Use Python and [CVXOPT](http://cvxopt.org) QP solver to implement the hard margin SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a matrix as 'data', its ground-truth 'labels' and trained parameters weight as 'w' and bias as 'b'\n",
    "# returns accuracy in percentage form.\n",
    "def get_accuracy(data,labels,w,b):\n",
    "    result = np.sign(np.dot(data, w) +b).astype(int) # sign(w^Tx + bias) as an integer 1 or -1\n",
    "    mul = np.multiply(result, labels) # Ground truth labels and predictions are multiplied. \n",
    "    # -1 * -1 makes 1, 1 * 1 makes 1 so this is correct classification.\n",
    "    acc = np.count_nonzero(mul == 1) / len(labels) # Correct classifications rate.\n",
    "    return acc*100 # % form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.2653e-01  1.9592e+00  6e+00  2e+00  4e+00\n",
      " 1:  1.5796e+00  8.5663e-01  7e-01  2e-16  1e-15\n",
      " 2:  1.0195e+00  9.9227e-01  3e-02  4e-16  9e-16\n",
      " 3:  1.0002e+00  9.9992e-01  3e-04  2e-16  2e-15\n",
      " 4:  1.0000e+00  1.0000e+00  3e-06  2e-16  1e-15\n",
      " 5:  1.0000e+00  1.0000e+00  3e-08  1e-16  8e-16\n",
      "Optimal solution found.\n",
      "weight: [ 1.00000001 -1.00000001]\n",
      "bias: -1.0000000134075104\n",
      "Train classification accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "from cvxopt import matrix, solvers # import required libraries\n",
    "X = np.array([[0, 0], [2, 2],[2,0],[3,0]]) # our toy data set from slides\n",
    "y = np.array([-1, -1, 1, 1])\n",
    "\n",
    "n ,dim = X.shape\n",
    "# initialize variables \n",
    "Q = matrix(np.identity(dim + 1, dtype=np.float)) # (m+1)x(m+1) identity matrix (0,0) element will be made 0\n",
    "p = matrix(np.zeros((dim + 1,), dtype=np.float)) # (m+1)x1 matrix of zeros\n",
    "A = matrix(np.zeros((n, dim + 1), dtype=np.float)) # nx(m+1) matrix\n",
    "c = -matrix(np.ones((n,), dtype=np.float)) # nx1 matrix full of -1s\n",
    "\n",
    "Q[0, 0] = 0\n",
    "\n",
    "for i in range(n):\n",
    "    A[i, 0] = -y[i]* 1. # first column of A is negated label values\n",
    "    A[i, 1:] = -y[i]*X[i, :]* 1. # other columns are  -y(i)*x(i,:)\n",
    "\n",
    "# cvxopt solver asks constraints in less than or equal to format \n",
    "# we calculated Au>=c in the class, so we transformed equation to -Au <= -c\n",
    "# Thats why we negated A and c\n",
    "# solver returns a vector [b,w]\n",
    "#solvers.options['show_progress'] = False # suppress output\n",
    "sol = solvers.qp(Q,p,A,c)\n",
    "\n",
    "w = np.zeros(dim,) # weight\n",
    "b = sol[\"x\"][0] # bias\n",
    "\n",
    "for i in range(1, dim + 1):\n",
    "    w[i - 1] = sol[\"x\"][i] # get weights from solution\n",
    "\n",
    "\n",
    "print(f\"weight: {w}\")\n",
    "print(f\"bias: {b}\")\n",
    "train_accuracy = get_accuracy(X,y,w,b) # get the accuracy of the model\n",
    "print(f\"Train classification accuracy: {train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
